From ba3c3b3a2820ea34bf69ab6499dac559a9dba81e Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Sat, 22 Apr 2017 13:56:33 -0400
Subject: [PATCH 01/45] backfill session cleanup

---
 airflow/executors/base_executor.py                 |  4 ++--
 airflow/models.py                                  |  3 +++
 airflow/ti_deps/deps/dag_ti_slots_available_dep.py |  2 +-
 airflow/ti_deps/deps/dag_unpaused_dep.py           |  2 +-
 airflow/utils/db.py                                | 12 ++++++++++--
 incubator-airflow.iml                              | 11 +++++++++++
 init.sh                                            |  0
 7 files changed, 28 insertions(+), 6 deletions(-)
 create mode 100644 incubator-airflow.iml
 mode change 100644 => 100755 init.sh

diff --git a/airflow/executors/base_executor.py b/airflow/executors/base_executor.py
index d3d0675..b8a0428 100644
--- a/airflow/executors/base_executor.py
+++ b/airflow/executors/base_executor.py
@@ -92,7 +92,7 @@ class BaseExecutor(LoggingMixin):
         """
         pass
 
-    def heartbeat(self):
+    def heartbeat(self, session=None):
 
         # Triggering new jobs
         if not self.parallelism:
@@ -118,7 +118,7 @@ class BaseExecutor(LoggingMixin):
             # Backfill. This fix reduces the probability of a collision but
             # does NOT eliminate it.
             self.queued_tasks.pop(key)
-            ti.refresh_from_db()
+            ti.refresh_from_db(session=session)
             if ti.state != State.RUNNING:
                 self.running[key] = command
                 self.execute_async(key, command=command, queue=queue)
diff --git a/airflow/models.py b/airflow/models.py
index 3e296eb..96c3641 100755
--- a/airflow/models.py
+++ b/airflow/models.py
@@ -3173,6 +3173,9 @@ class DAG(BaseDag, LoggingMixin):
     @property
     @provide_session
     def is_paused(self, session=None):
+        return self.check_paused(session=session)
+
+    def check_paused(self, session=None):
         """
         Returns a boolean indicating whether this DAG is paused
         """
diff --git a/airflow/ti_deps/deps/dag_ti_slots_available_dep.py b/airflow/ti_deps/deps/dag_ti_slots_available_dep.py
index 799d1cc..c46f37d 100644
--- a/airflow/ti_deps/deps/dag_ti_slots_available_dep.py
+++ b/airflow/ti_deps/deps/dag_ti_slots_available_dep.py
@@ -21,7 +21,7 @@ class DagTISlotsAvailableDep(BaseTIDep):
 
     @provide_session
     def _get_dep_statuses(self, ti, session, dep_context):
-        if ti.task.dag.concurrency_reached:
+        if ti.task.dag.concurrency_reached(session=session):
             yield self._failing_status(
                 reason="The maximum number of running tasks ({0}) for this task's DAG "
                        "'{1}' has been reached.".format(ti.task.dag.concurrency,
diff --git a/airflow/ti_deps/deps/dag_unpaused_dep.py b/airflow/ti_deps/deps/dag_unpaused_dep.py
index 6d6bf32..6249ace 100644
--- a/airflow/ti_deps/deps/dag_unpaused_dep.py
+++ b/airflow/ti_deps/deps/dag_unpaused_dep.py
@@ -21,6 +21,6 @@ class DagUnpausedDep(BaseTIDep):
 
     @provide_session
     def _get_dep_statuses(self, ti, session, dep_context):
-        if ti.task.dag.is_paused:
+        if ti.task.dag.check_paused(session=session):
             yield self._failing_status(
                 reason="Task's DAG '{0}' is paused.".format(ti.dag_id))
diff --git a/airflow/utils/db.py b/airflow/utils/db.py
index ef2560f..c3aabb3 100644
--- a/airflow/utils/db.py
+++ b/airflow/utils/db.py
@@ -41,10 +41,18 @@ def provide_session(func):
         needs_session = False
         arg_session = 'session'
         func_params = func.__code__.co_varnames
+
         session_in_args = arg_session in func_params and \
-            func_params.index(arg_session) < len(args)
-        if not (arg_session in kwargs or session_in_args):
+            func_params.index(arg_session) < len(args) and \
+            args[func_params.index(arg_session)] is not None
+
+        session_in_kwargs = arg_session in kwargs and \
+            kwargs[arg_session] is not None
+
+        if not (session_in_kwargs or session_in_args):
             needs_session = True
+            log.info("Injecting session into %s" % func.__name__)
+            # traceback.print_stack()
             session = settings.Session()
             kwargs[arg_session] = session
         result = func(*args, **kwargs)
diff --git a/incubator-airflow.iml b/incubator-airflow.iml
new file mode 100644
index 0000000..2046f7f
--- /dev/null
+++ b/incubator-airflow.iml
@@ -0,0 +1,11 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<module type="PYTHON_MODULE" version="4">
+  <component name="NewModuleRootManager" inherit-compiler-output="true">
+    <exclude-output />
+    <content url="file://$MODULE_DIR$">
+      <sourceFolder url="file://$MODULE_DIR$/airflow" isTestSource="false" />
+    </content>
+    <orderEntry type="inheritedJdk" />
+    <orderEntry type="sourceFolder" forTests="false" />
+  </component>
+</module>
\ No newline at end of file
diff --git a/init.sh b/init.sh
old mode 100644
new mode 100755
-- 
2.6.4 (Apple Git-63)


From 317c5cdb409c6a4019d1dfc9dc3627be2ab37ddd Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Sat, 22 Apr 2017 18:55:25 -0400
Subject: [PATCH 02/45] dag executor for individual dag runs in a backfill

---
 airflow/executors/base_executor.py | 4 +++-
 incubator-airflow.iml              | 1 +
 2 files changed, 4 insertions(+), 1 deletion(-)

diff --git a/airflow/executors/base_executor.py b/airflow/executors/base_executor.py
index b8a0428..543624b 100644
--- a/airflow/executors/base_executor.py
+++ b/airflow/executors/base_executor.py
@@ -58,7 +58,8 @@ class BaseExecutor(LoggingMixin):
             ignore_depends_on_past=False,
             ignore_task_deps=False,
             ignore_ti_state=False,
-            pool=None):
+            pool=None,
+            dag_executor=None):
         pool = pool or task_instance.pool
         command = task_instance.command(
             local=True,
@@ -68,6 +69,7 @@ class BaseExecutor(LoggingMixin):
             ignore_task_deps=ignore_task_deps,
             ignore_ti_state=ignore_ti_state,
             pool=pool,
+            dag_executor=dag_executor,
             pickle_id=pickle_id)
         self.queue_command(
             task_instance,
diff --git a/incubator-airflow.iml b/incubator-airflow.iml
index 2046f7f..1840d17 100644
--- a/incubator-airflow.iml
+++ b/incubator-airflow.iml
@@ -4,6 +4,7 @@
     <exclude-output />
     <content url="file://$MODULE_DIR$">
       <sourceFolder url="file://$MODULE_DIR$/airflow" isTestSource="false" />
+      <excludeFolder url="file://$MODULE_DIR$/build" />
     </content>
     <orderEntry type="inheritedJdk" />
     <orderEntry type="sourceFolder" forTests="false" />
-- 
2.6.4 (Apple Git-63)


From a0cd45d5d8e32dbce3a99d4a9b86db9b3a236aaf Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Fri, 28 Apr 2017 19:04:22 -0400
Subject: [PATCH 03/45] respect pool

---
 airflow/jobs.py | 15 +++++++++++++++
 1 file changed, 15 insertions(+)

diff --git a/airflow/jobs.py b/airflow/jobs.py
index e7fff31..fd85d3c 100644
--- a/airflow/jobs.py
+++ b/airflow/jobs.py
@@ -2160,6 +2160,9 @@ class BackfillJob(BaseJob):
             self.log.debug("*** Clearing out not_ready list ***")
             ti_status.not_ready.clear()
 
+            # Get the pool settings
+            pools = {p.pool: p for p in session.query(models.Pool).all()}
+
             # we need to execute the tasks bottom to top
             # or leaf to root, as otherwise tasks might be
             # determined deadlocked while they are actually
@@ -2171,6 +2174,18 @@ class BackfillJob(BaseJob):
 
                     ti.refresh_from_db()
 
+                    pool = ti.pool
+                    if not pool:
+                        # Arbitrary:
+                        # If queued outside of a pool, trigger no more than
+                        # non_pooled_task_slot_count per run
+                        open_slots = conf.getint('core', 'non_pooled_task_slot_count')
+                    else:
+                        open_slots = pools[pool].open_slots(session=session)
+
+                    if open_slots <= 0:
+                        logging.info("Pool full! Not scheduling task in pool %s".format(pool))
+
                     task = self.dag.get_task(ti.task_id)
                     ti.task = task
 
-- 
2.6.4 (Apple Git-63)


From 23fa30eb0e886a41989d79137bc59152b1cb8396 Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Fri, 28 Apr 2017 19:07:29 -0400
Subject: [PATCH 04/45] pool

---
 airflow/jobs.py | 3 ++-
 1 file changed, 2 insertions(+), 1 deletion(-)

diff --git a/airflow/jobs.py b/airflow/jobs.py
index fd85d3c..5188874 100644
--- a/airflow/jobs.py
+++ b/airflow/jobs.py
@@ -2184,7 +2184,8 @@ class BackfillJob(BaseJob):
                         open_slots = pools[pool].open_slots(session=session)
 
                     if open_slots <= 0:
-                        logging.info("Pool full! Not scheduling task in pool %s".format(pool))
+                        logging.info("Pool full! Not scheduling task in pool %s", pool)
+                        continue
 
                     task = self.dag.get_task(ti.task_id)
                     ti.task = task
-- 
2.6.4 (Apple Git-63)


From 8e5d13b29165c5e9dcfdcd176598fab8f555dfca Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Fri, 28 Apr 2017 20:20:36 -0400
Subject: [PATCH 05/45] queued fix

---
 airflow/jobs.py | 7 +++++--
 1 file changed, 5 insertions(+), 2 deletions(-)

diff --git a/airflow/jobs.py b/airflow/jobs.py
index 5188874..eac63b2 100644
--- a/airflow/jobs.py
+++ b/airflow/jobs.py
@@ -2184,7 +2184,7 @@ class BackfillJob(BaseJob):
                         open_slots = pools[pool].open_slots(session=session)
 
                     if open_slots <= 0:
-                        logging.info("Pool full! Not scheduling task in pool %s", pool)
+                        # logging.info("Pool full! Not scheduling task in pool %s", pool)
                         continue
 
                     task = self.dag.get_task(ti.task_id)
@@ -2247,7 +2247,10 @@ class BackfillJob(BaseJob):
                             session=session,
                             verbose=True):
                         ti.refresh_from_db(lock_for_update=True, session=session)
-                        if ti.state == State.SCHEDULED or ti.state == State.UP_FOR_RETRY:
+                        if ti.state == State.SCHEDULED \
+                            or ti.state == State.UP_FOR_RETRY \
+                            or ti.state == State.QUEUED:
+
                             if executor.has_task(ti):
                                 self.log.debug(
                                     "Task Instance %s already in executor waiting for queue to clear",
-- 
2.6.4 (Apple Git-63)


From 6566698c6d1c96a8722f443c982b5c780be1685f Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Wed, 3 May 2017 23:37:43 -0400
Subject: [PATCH 06/45] session trouble

---
 airflow/jobs.py | 3 +++
 1 file changed, 3 insertions(+)

diff --git a/airflow/jobs.py b/airflow/jobs.py
index eac63b2..a98bee4 100644
--- a/airflow/jobs.py
+++ b/airflow/jobs.py
@@ -2163,6 +2163,9 @@ class BackfillJob(BaseJob):
             # Get the pool settings
             pools = {p.pool: p for p in session.query(models.Pool).all()}
 
+            for p in pools.values():
+                session.expunge(p)
+
             # we need to execute the tasks bottom to top
             # or leaf to root, as otherwise tasks might be
             # determined deadlocked while they are actually
-- 
2.6.4 (Apple Git-63)


From e62c07169987898d88a1a2ee5d21fdee5516571a Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Fri, 5 May 2017 11:56:04 -0400
Subject: [PATCH 07/45] fix pandas version

---
 setup.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/setup.py b/setup.py
index 0a7658e..c36b315 100644
--- a/setup.py
+++ b/setup.py
@@ -226,7 +226,7 @@ def do_setup():
             'jinja2>=2.7.3, <2.9.0',
             'lxml>=3.6.0, <4.0',
             'markdown>=2.5.2, <3.0',
-            'pandas>=0.17.1, <1.0.0',
+            'pandas>=0.17.1, <0.20.0',
             'psutil>=4.2.0, <5.0.0',
             'pygments>=2.0.1, <3.0',
             'python-daemon>=2.1.1, <2.2',
-- 
2.6.4 (Apple Git-63)


From 73e919269403b8ba7fd7369600f2a320e497bbd9 Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Fri, 19 May 2017 19:09:39 -0400
Subject: [PATCH 08/45] Add prev_ds and next_ds to context

---
 airflow/models.py | 5 +++++
 1 file changed, 5 insertions(+)

diff --git a/airflow/models.py b/airflow/models.py
index 96c3641..4a500ab 100755
--- a/airflow/models.py
+++ b/airflow/models.py
@@ -1657,7 +1657,10 @@ class TaskInstance(Base, LoggingMixin):
         tomorrow_ds = (self.execution_date + timedelta(1)).isoformat()[:10]
 
         prev_execution_date = task.dag.previous_schedule(self.execution_date)
+        prev_ds = prev_execution_date.isoformat()[:10]
+
         next_execution_date = task.dag.following_schedule(self.execution_date)
+        next_ds = next_execution_date.isoformat()[:10]
 
         ds_nodash = ds.replace('-', '')
         ts_nodash = ts.replace('-', '').replace(':', '')
@@ -1729,7 +1732,9 @@ class TaskInstance(Base, LoggingMixin):
             'run_id': run_id,
             'execution_date': self.execution_date,
             'prev_execution_date': prev_execution_date,
+            'prev_ds': prev_ds,
             'next_execution_date': next_execution_date,
+            'next_ds': next_ds,
             'latest_date': ds,
             'macros': macros,
             'params': params,
-- 
2.6.4 (Apple Git-63)


From aa3d469e92f77cd7e8d2cec920b3955f7df5fdae Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Mon, 22 May 2017 12:19:51 -0400
Subject: [PATCH 09/45] Add month based templating vars

---
 airflow/models.py | 18 +++++++++++++++---
 1 file changed, 15 insertions(+), 3 deletions(-)

diff --git a/airflow/models.py b/airflow/models.py
index 4a500ab..7d2b660 100755
--- a/airflow/models.py
+++ b/airflow/models.py
@@ -17,6 +17,8 @@ from __future__ import division
 from __future__ import print_function
 from __future__ import unicode_literals
 
+import calendar
+
 from future.standard_library import install_aliases
 
 install_aliases()
@@ -24,7 +26,7 @@ from builtins import str
 from builtins import object, bytes
 import copy
 from collections import namedtuple
-from datetime import datetime, timedelta
+from datetime import datetime, timedelta, date
 import dill
 import functools
 import getpass
@@ -1655,17 +1657,21 @@ class TaskInstance(Base, LoggingMixin):
         ts = self.execution_date.isoformat()
         yesterday_ds = (self.execution_date - timedelta(1)).isoformat()[:10]
         tomorrow_ds = (self.execution_date + timedelta(1)).isoformat()[:10]
-
         prev_execution_date = task.dag.previous_schedule(self.execution_date)
         prev_ds = prev_execution_date.isoformat()[:10]
-
         next_execution_date = task.dag.following_schedule(self.execution_date)
         next_ds = next_execution_date.isoformat()[:10]
+        month_first_ds = self.execution_date.replace(day=1)
+        month_last_ds = self.execution_date.replace(day=calendar.calendar.monthrange(date.year, date.month)[1])
 
         ds_nodash = ds.replace('-', '')
         ts_nodash = ts.replace('-', '').replace(':', '')
         yesterday_ds_nodash = yesterday_ds.replace('-', '')
         tomorrow_ds_nodash = tomorrow_ds.replace('-', '')
+        prev_ds_nodash = prev_ds.replace('-', '')
+        next_ds_nodash = next_ds.replace('-', '')
+        month_first_ds_nodash = month_first_ds.replace('-', '')
+        month_last_ds_nodash = month_last_ds.replace('-', '')
 
         ti_key_str = "{task.dag_id}__{task.task_id}__{ds_nodash}"
         ti_key_str = ti_key_str.format(**locals())
@@ -1733,8 +1739,14 @@ class TaskInstance(Base, LoggingMixin):
             'execution_date': self.execution_date,
             'prev_execution_date': prev_execution_date,
             'prev_ds': prev_ds,
+            'prev_ds_nodash': prev_ds_nodash,
             'next_execution_date': next_execution_date,
             'next_ds': next_ds,
+            'next_ds_nodash': next_ds_nodash,
+            'month_first_ds': month_first_ds,
+            'month_first_ds_nodash': month_first_ds_nodash,
+            'month_last_ds': month_last_ds,
+            'month_last_ds_nodash': month_last_ds_nodash,
             'latest_date': ds,
             'macros': macros,
             'params': params,
-- 
2.6.4 (Apple Git-63)


From 84eb2b8fa9f2d0224d736517725e498b1534271e Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Mon, 22 May 2017 13:38:28 -0400
Subject: [PATCH 10/45] Fixed reference

---
 airflow/models.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/airflow/models.py b/airflow/models.py
index 7d2b660..65dc5d9 100755
--- a/airflow/models.py
+++ b/airflow/models.py
@@ -1662,7 +1662,7 @@ class TaskInstance(Base, LoggingMixin):
         next_execution_date = task.dag.following_schedule(self.execution_date)
         next_ds = next_execution_date.isoformat()[:10]
         month_first_ds = self.execution_date.replace(day=1)
-        month_last_ds = self.execution_date.replace(day=calendar.calendar.monthrange(date.year, date.month)[1])
+        month_last_ds = self.execution_date.replace(day=calendar.monthrange(date.year, date.month)[1])
 
         ds_nodash = ds.replace('-', '')
         ts_nodash = ts.replace('-', '').replace(':', '')
-- 
2.6.4 (Apple Git-63)


From 01f7ab393c0192a91cebbdb6609ef3e3e3367b0a Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Mon, 22 May 2017 14:14:21 -0400
Subject: [PATCH 11/45] Fix

---
 airflow/models.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/airflow/models.py b/airflow/models.py
index 65dc5d9..77314c1 100755
--- a/airflow/models.py
+++ b/airflow/models.py
@@ -1662,7 +1662,7 @@ class TaskInstance(Base, LoggingMixin):
         next_execution_date = task.dag.following_schedule(self.execution_date)
         next_ds = next_execution_date.isoformat()[:10]
         month_first_ds = self.execution_date.replace(day=1)
-        month_last_ds = self.execution_date.replace(day=calendar.monthrange(date.year, date.month)[1])
+        month_last_ds = self.execution_date.replace(day=calendar.monthrange(self.execution_date.year, self.execution_date.month)[1])
 
         ds_nodash = ds.replace('-', '')
         ts_nodash = ts.replace('-', '').replace(':', '')
-- 
2.6.4 (Apple Git-63)


From b9cfe752c667b0da7d65dbab056dcea340158506 Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Mon, 22 May 2017 14:19:48 -0400
Subject: [PATCH 12/45] Fixed

---
 airflow/models.py | 6 ++++--
 1 file changed, 4 insertions(+), 2 deletions(-)

diff --git a/airflow/models.py b/airflow/models.py
index 77314c1..add1d2b 100755
--- a/airflow/models.py
+++ b/airflow/models.py
@@ -1661,8 +1661,10 @@ class TaskInstance(Base, LoggingMixin):
         prev_ds = prev_execution_date.isoformat()[:10]
         next_execution_date = task.dag.following_schedule(self.execution_date)
         next_ds = next_execution_date.isoformat()[:10]
-        month_first_ds = self.execution_date.replace(day=1)
-        month_last_ds = self.execution_date.replace(day=calendar.monthrange(self.execution_date.year, self.execution_date.month)[1])
+        month_first_date = self.execution_date.replace(day=1)
+        month_first_ds = month_first_date.isoformat()[:10]
+        month_last_date = self.execution_date.replace(day=calendar.monthrange(self.execution_date.year, self.execution_date.month)[1])
+        month_last_ds = month_last_date.isoformat()[:10]
 
         ds_nodash = ds.replace('-', '')
         ts_nodash = ts.replace('-', '').replace(':', '')
-- 
2.6.4 (Apple Git-63)


From 849ceadd6807637ee04d29c5ee47a12ed7161e31 Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Wed, 28 Jun 2017 16:05:58 -0400
Subject: [PATCH 13/45] Use templates in templated fields

---
 airflow/models.py | 18 ++++++++++++++++--
 1 file changed, 16 insertions(+), 2 deletions(-)

diff --git a/airflow/models.py b/airflow/models.py
index add1d2b..ed84df3 100755
--- a/airflow/models.py
+++ b/airflow/models.py
@@ -1777,8 +1777,22 @@ class TaskInstance(Base, LoggingMixin):
         for attr in task.__class__.template_fields:
             content = getattr(task, attr)
             if content:
-                rendered_content = rt(attr, content, jinja_context)
-                setattr(task, attr, rendered_content)
+                last_content = content
+                done_rendering = False
+                iterations = 0
+                while not done_rendering:
+                    rendered_content = rt(attr, last_content, jinja_context)
+                    if iterations > 5:
+                        logging.info('Stuck in loop!!!!')
+                        break
+
+                    if last_content == rendered_content:
+                        done_rendering = True
+
+                    last_content = rendered_content
+                    iterations += 1
+
+                setattr(task, attr, last_content)
 
     def email_alert(self, exception, is_retry=False):
         task = self.task
-- 
2.6.4 (Apple Git-63)


From 46481f9eb997fd1f1de18e75a3ea0d0b6b34fe6a Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Tue, 1 Aug 2017 14:14:30 -0400
Subject: [PATCH 14/45] Reduce column id size to 191

---
 .../migrations/versions/1b38cef5b76e_add_dagrun.py |  4 ++--
 .../64de9cddf6c9_add_task_fails_journal_table.py   |  4 ++--
 .../versions/e3a246e0dc1_current_schema.py         | 28 +++++++++++-----------
 .../versions/f2ca10b85618_add_dag_stats_table.py   |  2 +-
 airflow/models.py                                  |  2 +-
 5 files changed, 20 insertions(+), 20 deletions(-)

diff --git a/airflow/migrations/versions/1b38cef5b76e_add_dagrun.py b/airflow/migrations/versions/1b38cef5b76e_add_dagrun.py
index 7da9ee7..f0bb31d 100644
--- a/airflow/migrations/versions/1b38cef5b76e_add_dagrun.py
+++ b/airflow/migrations/versions/1b38cef5b76e_add_dagrun.py
@@ -34,10 +34,10 @@ from sqlalchemy.dialects import mysql
 def upgrade():
     op.create_table('dag_run',
         sa.Column('id', sa.Integer(), nullable=False),
-        sa.Column('dag_id', sa.String(length=250), nullable=True),
+        sa.Column('dag_id', sa.String(length=191), nullable=True),
         sa.Column('execution_date', sa.DateTime(), nullable=True),
         sa.Column('state', sa.String(length=50), nullable=True),
-        sa.Column('run_id', sa.String(length=250), nullable=True),
+        sa.Column('run_id', sa.String(length=191), nullable=True),
         sa.Column('external_trigger', sa.Boolean(), nullable=True),
         sa.PrimaryKeyConstraint('id'),
         sa.UniqueConstraint('dag_id', 'execution_date'),
diff --git a/airflow/migrations/versions/64de9cddf6c9_add_task_fails_journal_table.py b/airflow/migrations/versions/64de9cddf6c9_add_task_fails_journal_table.py
index 3d5c7a4..1f38f34 100644
--- a/airflow/migrations/versions/64de9cddf6c9_add_task_fails_journal_table.py
+++ b/airflow/migrations/versions/64de9cddf6c9_add_task_fails_journal_table.py
@@ -33,8 +33,8 @@ def upgrade():
     op.create_table(
         'task_fail',
         sa.Column('id', sa.Integer(), nullable=False),
-        sa.Column('task_id', sa.String(length=250), nullable=False),
-        sa.Column('dag_id', sa.String(length=250), nullable=False),
+        sa.Column('task_id', sa.String(length=191), nullable=False),
+        sa.Column('dag_id', sa.String(length=191), nullable=False),
         sa.Column('execution_date', sa.DateTime(), nullable=False),
         sa.Column('start_date', sa.DateTime(), nullable=True),
         sa.Column('end_date', sa.DateTime(), nullable=True),
diff --git a/airflow/migrations/versions/e3a246e0dc1_current_schema.py b/airflow/migrations/versions/e3a246e0dc1_current_schema.py
index c1cb9c6..b6ca2e6 100644
--- a/airflow/migrations/versions/e3a246e0dc1_current_schema.py
+++ b/airflow/migrations/versions/e3a246e0dc1_current_schema.py
@@ -40,7 +40,7 @@ def upgrade():
         op.create_table(
             'connection',
             sa.Column('id', sa.Integer(), nullable=False),
-            sa.Column('conn_id', sa.String(length=250), nullable=True),
+            sa.Column('conn_id', sa.String(length=191), nullable=True),
             sa.Column('conn_type', sa.String(length=500), nullable=True),
             sa.Column('host', sa.String(length=500), nullable=True),
             sa.Column('schema', sa.String(length=500), nullable=True),
@@ -53,7 +53,7 @@ def upgrade():
     if 'dag' not in tables:
         op.create_table(
             'dag',
-            sa.Column('dag_id', sa.String(length=250), nullable=False),
+            sa.Column('dag_id', sa.String(length=191), nullable=False),
             sa.Column('is_paused', sa.Boolean(), nullable=True),
             sa.Column('is_subdag', sa.Boolean(), nullable=True),
             sa.Column('is_active', sa.Boolean(), nullable=True),
@@ -88,7 +88,7 @@ def upgrade():
         op.create_table(
             'job',
             sa.Column('id', sa.Integer(), nullable=False),
-            sa.Column('dag_id', sa.String(length=250), nullable=True),
+            sa.Column('dag_id', sa.String(length=191), nullable=True),
             sa.Column('state', sa.String(length=20), nullable=True),
             sa.Column('job_type', sa.String(length=30), nullable=True),
             sa.Column('start_date', sa.DateTime(), nullable=True),
@@ -117,8 +117,8 @@ def upgrade():
             'log',
             sa.Column('id', sa.Integer(), nullable=False),
             sa.Column('dttm', sa.DateTime(), nullable=True),
-            sa.Column('dag_id', sa.String(length=250), nullable=True),
-            sa.Column('task_id', sa.String(length=250), nullable=True),
+            sa.Column('dag_id', sa.String(length=191), nullable=True),
+            sa.Column('task_id', sa.String(length=191), nullable=True),
             sa.Column('event', sa.String(length=30), nullable=True),
             sa.Column('execution_date', sa.DateTime(), nullable=True),
             sa.Column('owner', sa.String(length=500), nullable=True),
@@ -127,8 +127,8 @@ def upgrade():
     if 'sla_miss' not in tables:
         op.create_table(
             'sla_miss',
-            sa.Column('task_id', sa.String(length=250), nullable=False),
-            sa.Column('dag_id', sa.String(length=250), nullable=False),
+            sa.Column('task_id', sa.String(length=191), nullable=False),
+            sa.Column('dag_id', sa.String(length=191), nullable=False),
             sa.Column('execution_date', sa.DateTime(), nullable=False),
             sa.Column('email_sent', sa.Boolean(), nullable=True),
             sa.Column('timestamp', sa.DateTime(), nullable=True),
@@ -148,8 +148,8 @@ def upgrade():
     if 'task_instance' not in tables:
         op.create_table(
             'task_instance',
-            sa.Column('task_id', sa.String(length=250), nullable=False),
-            sa.Column('dag_id', sa.String(length=250), nullable=False),
+            sa.Column('task_id', sa.String(length=191), nullable=False),
+            sa.Column('dag_id', sa.String(length=191), nullable=False),
             sa.Column('execution_date', sa.DateTime(), nullable=False),
             sa.Column('start_date', sa.DateTime(), nullable=True),
             sa.Column('end_date', sa.DateTime(), nullable=True),
@@ -187,7 +187,7 @@ def upgrade():
         op.create_table(
             'user',
             sa.Column('id', sa.Integer(), nullable=False),
-            sa.Column('username', sa.String(length=250), nullable=True),
+            sa.Column('username', sa.String(length=191), nullable=True),
             sa.Column('email', sa.String(length=500), nullable=True),
             sa.PrimaryKeyConstraint('id'),
             sa.UniqueConstraint('username')
@@ -196,7 +196,7 @@ def upgrade():
         op.create_table(
             'variable',
             sa.Column('id', sa.Integer(), nullable=False),
-            sa.Column('key', sa.String(length=250), nullable=True),
+            sa.Column('key', sa.String(length=191), nullable=True),
             sa.Column('val', sa.Text(), nullable=True),
             sa.PrimaryKeyConstraint('id'),
             sa.UniqueConstraint('key')
@@ -206,7 +206,7 @@ def upgrade():
             'chart',
             sa.Column('id', sa.Integer(), nullable=False),
             sa.Column('label', sa.String(length=200), nullable=True),
-            sa.Column('conn_id', sa.String(length=250), nullable=False),
+            sa.Column('conn_id', sa.String(length=191), nullable=False),
             sa.Column('user_id', sa.Integer(), nullable=True),
             sa.Column('chart_type', sa.String(length=100), nullable=True),
             sa.Column('sql_layout', sa.String(length=50), nullable=True),
@@ -249,8 +249,8 @@ def upgrade():
                 default=func.now(),
                 nullable=False),
             sa.Column('execution_date', sa.DateTime(), nullable=False),
-            sa.Column('task_id', sa.String(length=250), nullable=False),
-            sa.Column('dag_id', sa.String(length=250), nullable=False),
+            sa.Column('task_id', sa.String(length=191), nullable=False),
+            sa.Column('dag_id', sa.String(length=191), nullable=False),
             sa.PrimaryKeyConstraint('id')
         )
 
diff --git a/airflow/migrations/versions/f2ca10b85618_add_dag_stats_table.py b/airflow/migrations/versions/f2ca10b85618_add_dag_stats_table.py
index dabe812..0eb237f 100644
--- a/airflow/migrations/versions/f2ca10b85618_add_dag_stats_table.py
+++ b/airflow/migrations/versions/f2ca10b85618_add_dag_stats_table.py
@@ -31,7 +31,7 @@ import sqlalchemy as sa
 
 def upgrade():
     op.create_table('dag_stats',
-                    sa.Column('dag_id', sa.String(length=250), nullable=False),
+                    sa.Column('dag_id', sa.String(length=191), nullable=False),
                     sa.Column('state', sa.String(length=50), nullable=False),
                     sa.Column('count', sa.Integer(), nullable=False, default=0),
                     sa.Column('dirty', sa.Boolean(), nullable=False, default=False),
diff --git a/airflow/models.py b/airflow/models.py
index ed84df3..ea08fe7 100755
--- a/airflow/models.py
+++ b/airflow/models.py
@@ -84,7 +84,7 @@ from airflow.utils.trigger_rule import TriggerRule
 from airflow.utils.log.logging_mixin import LoggingMixin
 
 Base = declarative_base()
-ID_LEN = 250
+ID_LEN = 191
 XCOM_RETURN_KEY = 'return_value'
 
 Stats = settings.Stats
-- 
2.6.4 (Apple Git-63)


From 3cfbcf1a7edae1f5bef6203f374d0409101e0429 Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Tue, 1 Aug 2017 14:28:09 -0400
Subject: [PATCH 15/45] Ignore fractional seconds to support older mysql

---
 ...236f1_add_fractional_seconds_to_mysql_tables.py | 52 +++++++++++-----------
 1 file changed, 26 insertions(+), 26 deletions(-)

diff --git a/airflow/migrations/versions/4addfa1236f1_add_fractional_seconds_to_mysql_tables.py b/airflow/migrations/versions/4addfa1236f1_add_fractional_seconds_to_mysql_tables.py
index c1c6de3..053b120 100644
--- a/airflow/migrations/versions/4addfa1236f1_add_fractional_seconds_to_mysql_tables.py
+++ b/airflow/migrations/versions/4addfa1236f1_add_fractional_seconds_to_mysql_tables.py
@@ -33,42 +33,42 @@ from alembic import context
 
 def upgrade():
     if context.config.get_main_option('sqlalchemy.url').startswith('mysql'):
-        op.alter_column(table_name='dag', column_name='last_scheduler_run', type_=mysql.DATETIME(fsp=6))
-        op.alter_column(table_name='dag', column_name='last_pickled', type_=mysql.DATETIME(fsp=6))
-        op.alter_column(table_name='dag', column_name='last_expired', type_=mysql.DATETIME(fsp=6))
+        op.alter_column(table_name='dag', column_name='last_scheduler_run', type_=mysql.DATETIME())
+        op.alter_column(table_name='dag', column_name='last_pickled', type_=mysql.DATETIME())
+        op.alter_column(table_name='dag', column_name='last_expired', type_=mysql.DATETIME())
 
-        op.alter_column(table_name='dag_pickle', column_name='created_dttm', type_=mysql.DATETIME(fsp=6))
+        op.alter_column(table_name='dag_pickle', column_name='created_dttm', type_=mysql.DATETIME())
 
-        op.alter_column(table_name='dag_run', column_name='execution_date', type_=mysql.DATETIME(fsp=6))
-        op.alter_column(table_name='dag_run', column_name='start_date', type_=mysql.DATETIME(fsp=6))
-        op.alter_column(table_name='dag_run', column_name='end_date', type_=mysql.DATETIME(fsp=6))
+        op.alter_column(table_name='dag_run', column_name='execution_date', type_=mysql.DATETIME())
+        op.alter_column(table_name='dag_run', column_name='start_date', type_=mysql.DATETIME())
+        op.alter_column(table_name='dag_run', column_name='end_date', type_=mysql.DATETIME())
 
-        op.alter_column(table_name='import_error', column_name='timestamp', type_=mysql.DATETIME(fsp=6))
+        op.alter_column(table_name='import_error', column_name='timestamp', type_=mysql.DATETIME())
 
-        op.alter_column(table_name='job', column_name='start_date', type_=mysql.DATETIME(fsp=6))
-        op.alter_column(table_name='job', column_name='end_date', type_=mysql.DATETIME(fsp=6))
-        op.alter_column(table_name='job', column_name='latest_heartbeat', type_=mysql.DATETIME(fsp=6))
+        op.alter_column(table_name='job', column_name='start_date', type_=mysql.DATETIME())
+        op.alter_column(table_name='job', column_name='end_date', type_=mysql.DATETIME())
+        op.alter_column(table_name='job', column_name='latest_heartbeat', type_=mysql.DATETIME())
 
-        op.alter_column(table_name='known_event', column_name='start_date', type_=mysql.DATETIME(fsp=6))
-        op.alter_column(table_name='known_event', column_name='end_date', type_=mysql.DATETIME(fsp=6))
+        op.alter_column(table_name='known_event', column_name='start_date', type_=mysql.DATETIME())
+        op.alter_column(table_name='known_event', column_name='end_date', type_=mysql.DATETIME())
 
-        op.alter_column(table_name='log', column_name='dttm', type_=mysql.DATETIME(fsp=6))
-        op.alter_column(table_name='log', column_name='execution_date', type_=mysql.DATETIME(fsp=6))
+        op.alter_column(table_name='log', column_name='dttm', type_=mysql.DATETIME())
+        op.alter_column(table_name='log', column_name='execution_date', type_=mysql.DATETIME())
 
-        op.alter_column(table_name='sla_miss', column_name='execution_date', type_=mysql.DATETIME(fsp=6), nullable=False)
-        op.alter_column(table_name='sla_miss', column_name='timestamp', type_=mysql.DATETIME(fsp=6))
+        op.alter_column(table_name='sla_miss', column_name='execution_date', type_=mysql.DATETIME(), nullable=False)
+        op.alter_column(table_name='sla_miss', column_name='timestamp', type_=mysql.DATETIME())
 
-        op.alter_column(table_name='task_fail', column_name='execution_date', type_=mysql.DATETIME(fsp=6))
-        op.alter_column(table_name='task_fail', column_name='start_date', type_=mysql.DATETIME(fsp=6))
-        op.alter_column(table_name='task_fail', column_name='end_date', type_=mysql.DATETIME(fsp=6))
+        op.alter_column(table_name='task_fail', column_name='execution_date', type_=mysql.DATETIME())
+        op.alter_column(table_name='task_fail', column_name='start_date', type_=mysql.DATETIME())
+        op.alter_column(table_name='task_fail', column_name='end_date', type_=mysql.DATETIME())
 
-        op.alter_column(table_name='task_instance', column_name='execution_date', type_=mysql.DATETIME(fsp=6), nullable=False)
-        op.alter_column(table_name='task_instance', column_name='start_date', type_=mysql.DATETIME(fsp=6))
-        op.alter_column(table_name='task_instance', column_name='end_date', type_=mysql.DATETIME(fsp=6))
-        op.alter_column(table_name='task_instance', column_name='queued_dttm', type_=mysql.DATETIME(fsp=6))
+        op.alter_column(table_name='task_instance', column_name='execution_date', type_=mysql.DATETIME(), nullable=False)
+        op.alter_column(table_name='task_instance', column_name='start_date', type_=mysql.DATETIME())
+        op.alter_column(table_name='task_instance', column_name='end_date', type_=mysql.DATETIME())
+        op.alter_column(table_name='task_instance', column_name='queued_dttm', type_=mysql.DATETIME())
 
-        op.alter_column(table_name='xcom', column_name='timestamp', type_=mysql.DATETIME(fsp=6))
-        op.alter_column(table_name='xcom', column_name='execution_date', type_=mysql.DATETIME(fsp=6))
+        op.alter_column(table_name='xcom', column_name='timestamp', type_=mysql.DATETIME())
+        op.alter_column(table_name='xcom', column_name='execution_date', type_=mysql.DATETIME())
 
 
 def downgrade():
-- 
2.6.4 (Apple Git-63)


From 6953468298952018f120ae1fd3b9601580a8a366 Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Sat, 19 Aug 2017 08:37:50 -0400
Subject: [PATCH 16/45] Include all dag states in latest run

---
 airflow/models.py                         | 24 +++++++++++++++++++++++-
 airflow/www/api/experimental/endpoints.py |  2 +-
 2 files changed, 24 insertions(+), 2 deletions(-)

diff --git a/airflow/models.py b/airflow/models.py
index ea08fe7..fa7c2db 100755
--- a/airflow/models.py
+++ b/airflow/models.py
@@ -26,7 +26,7 @@ from builtins import str
 from builtins import object, bytes
 import copy
 from collections import namedtuple
-from datetime import datetime, timedelta, date
+from datetime import datetime, timedelta
 import dill
 import functools
 import getpass
@@ -4764,6 +4764,28 @@ class DagRun(Base, LoggingMixin):
         )
         return dagruns
 
+    @classmethod
+    @provide_session
+    def get_all_latest_runs(cls, session):
+        """Returns the latest running DagRun for each DAG. """
+        subquery = (
+            session
+            .query(
+                cls.dag_id,
+                func.max(cls.execution_date).label('execution_date'))
+            .group_by(cls.dag_id)
+            .subquery()
+        )
+        dagruns = (
+            session
+            .query(cls)
+            .join(subquery,
+                  and_(cls.dag_id == subquery.c.dag_id,
+                       cls.execution_date == subquery.c.execution_date))
+            .all()
+        )
+        return dagruns
+
 
 class Pool(Base):
     __tablename__ = "slot_pool"
diff --git a/airflow/www/api/experimental/endpoints.py b/airflow/www/api/experimental/endpoints.py
index b5a3052..b83c5b5 100644
--- a/airflow/www/api/experimental/endpoints.py
+++ b/airflow/www/api/experimental/endpoints.py
@@ -156,7 +156,7 @@ def task_instance_info(dag_id, execution_date, task_id):
 def latest_dag_runs():
     """Returns the latest DagRun for each DAG formatted for the UI. """
     from airflow.models import DagRun
-    dagruns = DagRun.get_latest_runs()
+    dagruns = DagRun.get_all_latest_runs()
     payload = []
     for dagrun in dagruns:
         if dagrun.execution_date:
-- 
2.6.4 (Apple Git-63)


From 36c2fbb68f2dde78288e7b73ee2e76f03fe25205 Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Wed, 20 Sep 2017 16:38:24 -0400
Subject: [PATCH 17/45] Remove excessive logging

---
 airflow/utils/db.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/airflow/utils/db.py b/airflow/utils/db.py
index c3aabb3..463ec8a 100644
--- a/airflow/utils/db.py
+++ b/airflow/utils/db.py
@@ -51,7 +51,7 @@ def provide_session(func):
 
         if not (session_in_kwargs or session_in_args):
             needs_session = True
-            log.info("Injecting session into %s" % func.__name__)
+            #logging.info("Injecting session into %s" % func.__name__)
             # traceback.print_stack()
             session = settings.Session()
             kwargs[arg_session] = session
-- 
2.6.4 (Apple Git-63)


From 29efc534cc7ceccd91a1de908cefe5c628257f2b Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Thu, 5 Oct 2017 16:26:36 -0400
Subject: [PATCH 18/45] None checks around prev_ds

---
 airflow/models.py | 8 ++++----
 1 file changed, 4 insertions(+), 4 deletions(-)

diff --git a/airflow/models.py b/airflow/models.py
index fa7c2db..c4dff63 100755
--- a/airflow/models.py
+++ b/airflow/models.py
@@ -1658,9 +1658,9 @@ class TaskInstance(Base, LoggingMixin):
         yesterday_ds = (self.execution_date - timedelta(1)).isoformat()[:10]
         tomorrow_ds = (self.execution_date + timedelta(1)).isoformat()[:10]
         prev_execution_date = task.dag.previous_schedule(self.execution_date)
-        prev_ds = prev_execution_date.isoformat()[:10]
+        prev_ds = prev_execution_date.isoformat()[:10] if prev_execution_date else None
         next_execution_date = task.dag.following_schedule(self.execution_date)
-        next_ds = next_execution_date.isoformat()[:10]
+        next_ds = next_execution_date.isoformat()[:10] if next_execution_date else None
         month_first_date = self.execution_date.replace(day=1)
         month_first_ds = month_first_date.isoformat()[:10]
         month_last_date = self.execution_date.replace(day=calendar.monthrange(self.execution_date.year, self.execution_date.month)[1])
@@ -1670,8 +1670,8 @@ class TaskInstance(Base, LoggingMixin):
         ts_nodash = ts.replace('-', '').replace(':', '')
         yesterday_ds_nodash = yesterday_ds.replace('-', '')
         tomorrow_ds_nodash = tomorrow_ds.replace('-', '')
-        prev_ds_nodash = prev_ds.replace('-', '')
-        next_ds_nodash = next_ds.replace('-', '')
+        prev_ds_nodash = prev_ds.replace('-', '') if prev_ds else None
+        next_ds_nodash = next_ds.replace('-', '') if next_ds else None
         month_first_ds_nodash = month_first_ds.replace('-', '')
         month_last_ds_nodash = month_last_ds.replace('-', '')
 
-- 
2.6.4 (Apple Git-63)


From ab55923461dcfe5d64e2103b14cb56368f3e6ab0 Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Mon, 6 Nov 2017 15:15:58 -0500
Subject: [PATCH 19/45] Post merge 1.9

---
 airflow/task_runner/base_task_runner.py   | 3 ---
 airflow/utils/db.py                       | 2 --
 airflow/www/api/experimental/endpoints.py | 2 +-
 3 files changed, 1 insertion(+), 6 deletions(-)

diff --git a/airflow/task_runner/base_task_runner.py b/airflow/task_runner/base_task_runner.py
index ef4112d..963691e 100644
--- a/airflow/task_runner/base_task_runner.py
+++ b/airflow/task_runner/base_task_runner.py
@@ -11,7 +11,6 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from __future__ import unicode_literals
 
 import getpass
 import os
@@ -19,8 +18,6 @@ import json
 import subprocess
 import threading
 
-from airflow.utils.log.logging_mixin import LoggingMixin
-
 from airflow import configuration as conf
 from tempfile import mkstemp
 
diff --git a/airflow/utils/db.py b/airflow/utils/db.py
index 463ec8a..e85592d 100644
--- a/airflow/utils/db.py
+++ b/airflow/utils/db.py
@@ -51,8 +51,6 @@ def provide_session(func):
 
         if not (session_in_kwargs or session_in_args):
             needs_session = True
-            #logging.info("Injecting session into %s" % func.__name__)
-            # traceback.print_stack()
             session = settings.Session()
             kwargs[arg_session] = session
         result = func(*args, **kwargs)
diff --git a/airflow/www/api/experimental/endpoints.py b/airflow/www/api/experimental/endpoints.py
index b83c5b5..b5a3052 100644
--- a/airflow/www/api/experimental/endpoints.py
+++ b/airflow/www/api/experimental/endpoints.py
@@ -156,7 +156,7 @@ def task_instance_info(dag_id, execution_date, task_id):
 def latest_dag_runs():
     """Returns the latest DagRun for each DAG formatted for the UI. """
     from airflow.models import DagRun
-    dagruns = DagRun.get_all_latest_runs()
+    dagruns = DagRun.get_latest_runs()
     payload = []
     for dagrun in dagruns:
         if dagrun.execution_date:
-- 
2.6.4 (Apple Git-63)


From 91d59c8f3aa6dfaebe5bad1507aa7fb467d82f26 Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Mon, 6 Nov 2017 19:19:03 -0500
Subject: [PATCH 20/45] fixed merge

---
 airflow/ti_deps/deps/dag_ti_slots_available_dep.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/airflow/ti_deps/deps/dag_ti_slots_available_dep.py b/airflow/ti_deps/deps/dag_ti_slots_available_dep.py
index c46f37d..799d1cc 100644
--- a/airflow/ti_deps/deps/dag_ti_slots_available_dep.py
+++ b/airflow/ti_deps/deps/dag_ti_slots_available_dep.py
@@ -21,7 +21,7 @@ class DagTISlotsAvailableDep(BaseTIDep):
 
     @provide_session
     def _get_dep_statuses(self, ti, session, dep_context):
-        if ti.task.dag.concurrency_reached(session=session):
+        if ti.task.dag.concurrency_reached:
             yield self._failing_status(
                 reason="The maximum number of running tasks ({0}) for this task's DAG "
                        "'{1}' has been reached.".format(ti.task.dag.concurrency,
-- 
2.6.4 (Apple Git-63)


From 46423a4be01436daa4e19be643547a8a8e3339a6 Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Mon, 6 Nov 2017 21:31:45 -0500
Subject: [PATCH 21/45] removed executor

---
 airflow/executors/base_executor.py | 4 +---
 1 file changed, 1 insertion(+), 3 deletions(-)

diff --git a/airflow/executors/base_executor.py b/airflow/executors/base_executor.py
index 543624b..b8a0428 100644
--- a/airflow/executors/base_executor.py
+++ b/airflow/executors/base_executor.py
@@ -58,8 +58,7 @@ class BaseExecutor(LoggingMixin):
             ignore_depends_on_past=False,
             ignore_task_deps=False,
             ignore_ti_state=False,
-            pool=None,
-            dag_executor=None):
+            pool=None):
         pool = pool or task_instance.pool
         command = task_instance.command(
             local=True,
@@ -69,7 +68,6 @@ class BaseExecutor(LoggingMixin):
             ignore_task_deps=ignore_task_deps,
             ignore_ti_state=ignore_ti_state,
             pool=pool,
-            dag_executor=dag_executor,
             pickle_id=pickle_id)
         self.queue_command(
             task_instance,
-- 
2.6.4 (Apple Git-63)


From ba9e21dc3ff41d0b8696e4ab3c80c666e5b6f5b2 Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Tue, 19 Dec 2017 17:33:25 -0500
Subject: [PATCH 22/45] logging mixin

---
 airflow/task_runner/base_task_runner.py | 1 +
 1 file changed, 1 insertion(+)

diff --git a/airflow/task_runner/base_task_runner.py b/airflow/task_runner/base_task_runner.py
index 963691e..3ac99f4 100644
--- a/airflow/task_runner/base_task_runner.py
+++ b/airflow/task_runner/base_task_runner.py
@@ -18,6 +18,7 @@ import json
 import subprocess
 import threading
 
+from airflow import LoggingMixin
 from airflow import configuration as conf
 from tempfile import mkstemp
 
-- 
2.6.4 (Apple Git-63)


From b44d7b6ae3d0a13251858bd9f424de91f6a67c32 Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Sat, 22 Apr 2017 18:55:25 -0400
Subject: [PATCH 23/45] dag executor for individual dag runs in a backfill

---
 airflow/executors/base_executor.py | 4 +++-
 incubator-airflow.iml              | 1 +
 2 files changed, 4 insertions(+), 1 deletion(-)

diff --git a/airflow/executors/base_executor.py b/airflow/executors/base_executor.py
index b8a0428..543624b 100644
--- a/airflow/executors/base_executor.py
+++ b/airflow/executors/base_executor.py
@@ -58,7 +58,8 @@ class BaseExecutor(LoggingMixin):
             ignore_depends_on_past=False,
             ignore_task_deps=False,
             ignore_ti_state=False,
-            pool=None):
+            pool=None,
+            dag_executor=None):
         pool = pool or task_instance.pool
         command = task_instance.command(
             local=True,
@@ -68,6 +69,7 @@ class BaseExecutor(LoggingMixin):
             ignore_task_deps=ignore_task_deps,
             ignore_ti_state=ignore_ti_state,
             pool=pool,
+            dag_executor=dag_executor,
             pickle_id=pickle_id)
         self.queue_command(
             task_instance,
diff --git a/incubator-airflow.iml b/incubator-airflow.iml
index 2046f7f..1840d17 100644
--- a/incubator-airflow.iml
+++ b/incubator-airflow.iml
@@ -4,6 +4,7 @@
     <exclude-output />
     <content url="file://$MODULE_DIR$">
       <sourceFolder url="file://$MODULE_DIR$/airflow" isTestSource="false" />
+      <excludeFolder url="file://$MODULE_DIR$/build" />
     </content>
     <orderEntry type="inheritedJdk" />
     <orderEntry type="sourceFolder" forTests="false" />
-- 
2.6.4 (Apple Git-63)


From 1e95ad1dd3782a10ee76147870fa61b9e7f082d4 Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Fri, 28 Apr 2017 19:04:22 -0400
Subject: [PATCH 24/45] respect pool

---
 airflow/jobs.py | 15 +++++++++++++++
 1 file changed, 15 insertions(+)

diff --git a/airflow/jobs.py b/airflow/jobs.py
index e7fff31..fd85d3c 100644
--- a/airflow/jobs.py
+++ b/airflow/jobs.py
@@ -2160,6 +2160,9 @@ class BackfillJob(BaseJob):
             self.log.debug("*** Clearing out not_ready list ***")
             ti_status.not_ready.clear()
 
+            # Get the pool settings
+            pools = {p.pool: p for p in session.query(models.Pool).all()}
+
             # we need to execute the tasks bottom to top
             # or leaf to root, as otherwise tasks might be
             # determined deadlocked while they are actually
@@ -2171,6 +2174,18 @@ class BackfillJob(BaseJob):
 
                     ti.refresh_from_db()
 
+                    pool = ti.pool
+                    if not pool:
+                        # Arbitrary:
+                        # If queued outside of a pool, trigger no more than
+                        # non_pooled_task_slot_count per run
+                        open_slots = conf.getint('core', 'non_pooled_task_slot_count')
+                    else:
+                        open_slots = pools[pool].open_slots(session=session)
+
+                    if open_slots <= 0:
+                        logging.info("Pool full! Not scheduling task in pool %s".format(pool))
+
                     task = self.dag.get_task(ti.task_id)
                     ti.task = task
 
-- 
2.6.4 (Apple Git-63)


From e038d59ab8bfc74f8b811302ba4affc03b2f1d27 Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Fri, 28 Apr 2017 19:07:29 -0400
Subject: [PATCH 25/45] pool

---
 airflow/jobs.py | 3 ++-
 1 file changed, 2 insertions(+), 1 deletion(-)

diff --git a/airflow/jobs.py b/airflow/jobs.py
index fd85d3c..5188874 100644
--- a/airflow/jobs.py
+++ b/airflow/jobs.py
@@ -2184,7 +2184,8 @@ class BackfillJob(BaseJob):
                         open_slots = pools[pool].open_slots(session=session)
 
                     if open_slots <= 0:
-                        logging.info("Pool full! Not scheduling task in pool %s".format(pool))
+                        logging.info("Pool full! Not scheduling task in pool %s", pool)
+                        continue
 
                     task = self.dag.get_task(ti.task_id)
                     ti.task = task
-- 
2.6.4 (Apple Git-63)


From 8196fcfc4f8de6d41c42df35b47e71d8aa25c44d Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Fri, 28 Apr 2017 20:20:36 -0400
Subject: [PATCH 26/45] queued fix

---
 airflow/jobs.py | 7 +++++--
 1 file changed, 5 insertions(+), 2 deletions(-)

diff --git a/airflow/jobs.py b/airflow/jobs.py
index 5188874..eac63b2 100644
--- a/airflow/jobs.py
+++ b/airflow/jobs.py
@@ -2184,7 +2184,7 @@ class BackfillJob(BaseJob):
                         open_slots = pools[pool].open_slots(session=session)
 
                     if open_slots <= 0:
-                        logging.info("Pool full! Not scheduling task in pool %s", pool)
+                        # logging.info("Pool full! Not scheduling task in pool %s", pool)
                         continue
 
                     task = self.dag.get_task(ti.task_id)
@@ -2247,7 +2247,10 @@ class BackfillJob(BaseJob):
                             session=session,
                             verbose=True):
                         ti.refresh_from_db(lock_for_update=True, session=session)
-                        if ti.state == State.SCHEDULED or ti.state == State.UP_FOR_RETRY:
+                        if ti.state == State.SCHEDULED \
+                            or ti.state == State.UP_FOR_RETRY \
+                            or ti.state == State.QUEUED:
+
                             if executor.has_task(ti):
                                 self.log.debug(
                                     "Task Instance %s already in executor waiting for queue to clear",
-- 
2.6.4 (Apple Git-63)


From cbe073f1683bd5c25407191df2f247b8bad4daf5 Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Wed, 3 May 2017 23:37:43 -0400
Subject: [PATCH 27/45] session trouble

---
 airflow/jobs.py | 3 +++
 1 file changed, 3 insertions(+)

diff --git a/airflow/jobs.py b/airflow/jobs.py
index eac63b2..a98bee4 100644
--- a/airflow/jobs.py
+++ b/airflow/jobs.py
@@ -2163,6 +2163,9 @@ class BackfillJob(BaseJob):
             # Get the pool settings
             pools = {p.pool: p for p in session.query(models.Pool).all()}
 
+            for p in pools.values():
+                session.expunge(p)
+
             # we need to execute the tasks bottom to top
             # or leaf to root, as otherwise tasks might be
             # determined deadlocked while they are actually
-- 
2.6.4 (Apple Git-63)


From c9e3922ded03c2ce60995fb3c3fb40088e1ed688 Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Fri, 5 May 2017 11:56:04 -0400
Subject: [PATCH 28/45] fix pandas version

---
 setup.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/setup.py b/setup.py
index 0a7658e..c36b315 100644
--- a/setup.py
+++ b/setup.py
@@ -226,7 +226,7 @@ def do_setup():
             'jinja2>=2.7.3, <2.9.0',
             'lxml>=3.6.0, <4.0',
             'markdown>=2.5.2, <3.0',
-            'pandas>=0.17.1, <1.0.0',
+            'pandas>=0.17.1, <0.20.0',
             'psutil>=4.2.0, <5.0.0',
             'pygments>=2.0.1, <3.0',
             'python-daemon>=2.1.1, <2.2',
-- 
2.6.4 (Apple Git-63)


From 80d1238f4519694391424950ae5fb6098f8e2e7b Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Fri, 19 May 2017 19:09:39 -0400
Subject: [PATCH 29/45] Add prev_ds and next_ds to context

---
 airflow/models.py | 5 +++++
 1 file changed, 5 insertions(+)

diff --git a/airflow/models.py b/airflow/models.py
index 96c3641..4a500ab 100755
--- a/airflow/models.py
+++ b/airflow/models.py
@@ -1657,7 +1657,10 @@ class TaskInstance(Base, LoggingMixin):
         tomorrow_ds = (self.execution_date + timedelta(1)).isoformat()[:10]
 
         prev_execution_date = task.dag.previous_schedule(self.execution_date)
+        prev_ds = prev_execution_date.isoformat()[:10]
+
         next_execution_date = task.dag.following_schedule(self.execution_date)
+        next_ds = next_execution_date.isoformat()[:10]
 
         ds_nodash = ds.replace('-', '')
         ts_nodash = ts.replace('-', '').replace(':', '')
@@ -1729,7 +1732,9 @@ class TaskInstance(Base, LoggingMixin):
             'run_id': run_id,
             'execution_date': self.execution_date,
             'prev_execution_date': prev_execution_date,
+            'prev_ds': prev_ds,
             'next_execution_date': next_execution_date,
+            'next_ds': next_ds,
             'latest_date': ds,
             'macros': macros,
             'params': params,
-- 
2.6.4 (Apple Git-63)


From 2ecac67de0821c05978c575550303cc3a29b21ef Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Mon, 22 May 2017 12:19:51 -0400
Subject: [PATCH 30/45] Add month based templating vars

---
 airflow/models.py | 18 +++++++++++++++---
 1 file changed, 15 insertions(+), 3 deletions(-)

diff --git a/airflow/models.py b/airflow/models.py
index 4a500ab..7d2b660 100755
--- a/airflow/models.py
+++ b/airflow/models.py
@@ -17,6 +17,8 @@ from __future__ import division
 from __future__ import print_function
 from __future__ import unicode_literals
 
+import calendar
+
 from future.standard_library import install_aliases
 
 install_aliases()
@@ -24,7 +26,7 @@ from builtins import str
 from builtins import object, bytes
 import copy
 from collections import namedtuple
-from datetime import datetime, timedelta
+from datetime import datetime, timedelta, date
 import dill
 import functools
 import getpass
@@ -1655,17 +1657,21 @@ class TaskInstance(Base, LoggingMixin):
         ts = self.execution_date.isoformat()
         yesterday_ds = (self.execution_date - timedelta(1)).isoformat()[:10]
         tomorrow_ds = (self.execution_date + timedelta(1)).isoformat()[:10]
-
         prev_execution_date = task.dag.previous_schedule(self.execution_date)
         prev_ds = prev_execution_date.isoformat()[:10]
-
         next_execution_date = task.dag.following_schedule(self.execution_date)
         next_ds = next_execution_date.isoformat()[:10]
+        month_first_ds = self.execution_date.replace(day=1)
+        month_last_ds = self.execution_date.replace(day=calendar.calendar.monthrange(date.year, date.month)[1])
 
         ds_nodash = ds.replace('-', '')
         ts_nodash = ts.replace('-', '').replace(':', '')
         yesterday_ds_nodash = yesterday_ds.replace('-', '')
         tomorrow_ds_nodash = tomorrow_ds.replace('-', '')
+        prev_ds_nodash = prev_ds.replace('-', '')
+        next_ds_nodash = next_ds.replace('-', '')
+        month_first_ds_nodash = month_first_ds.replace('-', '')
+        month_last_ds_nodash = month_last_ds.replace('-', '')
 
         ti_key_str = "{task.dag_id}__{task.task_id}__{ds_nodash}"
         ti_key_str = ti_key_str.format(**locals())
@@ -1733,8 +1739,14 @@ class TaskInstance(Base, LoggingMixin):
             'execution_date': self.execution_date,
             'prev_execution_date': prev_execution_date,
             'prev_ds': prev_ds,
+            'prev_ds_nodash': prev_ds_nodash,
             'next_execution_date': next_execution_date,
             'next_ds': next_ds,
+            'next_ds_nodash': next_ds_nodash,
+            'month_first_ds': month_first_ds,
+            'month_first_ds_nodash': month_first_ds_nodash,
+            'month_last_ds': month_last_ds,
+            'month_last_ds_nodash': month_last_ds_nodash,
             'latest_date': ds,
             'macros': macros,
             'params': params,
-- 
2.6.4 (Apple Git-63)


From ddcfd098bd0d1a8ca9f6445af355bcc8c10d03cd Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Mon, 22 May 2017 13:38:28 -0400
Subject: [PATCH 31/45] Fixed reference

---
 airflow/models.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/airflow/models.py b/airflow/models.py
index 7d2b660..65dc5d9 100755
--- a/airflow/models.py
+++ b/airflow/models.py
@@ -1662,7 +1662,7 @@ class TaskInstance(Base, LoggingMixin):
         next_execution_date = task.dag.following_schedule(self.execution_date)
         next_ds = next_execution_date.isoformat()[:10]
         month_first_ds = self.execution_date.replace(day=1)
-        month_last_ds = self.execution_date.replace(day=calendar.calendar.monthrange(date.year, date.month)[1])
+        month_last_ds = self.execution_date.replace(day=calendar.monthrange(date.year, date.month)[1])
 
         ds_nodash = ds.replace('-', '')
         ts_nodash = ts.replace('-', '').replace(':', '')
-- 
2.6.4 (Apple Git-63)


From 9720d8d69ea5d582845fe5c63823ebab73d0eb84 Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Mon, 22 May 2017 14:14:21 -0400
Subject: [PATCH 32/45] Fix

---
 airflow/models.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/airflow/models.py b/airflow/models.py
index 65dc5d9..77314c1 100755
--- a/airflow/models.py
+++ b/airflow/models.py
@@ -1662,7 +1662,7 @@ class TaskInstance(Base, LoggingMixin):
         next_execution_date = task.dag.following_schedule(self.execution_date)
         next_ds = next_execution_date.isoformat()[:10]
         month_first_ds = self.execution_date.replace(day=1)
-        month_last_ds = self.execution_date.replace(day=calendar.monthrange(date.year, date.month)[1])
+        month_last_ds = self.execution_date.replace(day=calendar.monthrange(self.execution_date.year, self.execution_date.month)[1])
 
         ds_nodash = ds.replace('-', '')
         ts_nodash = ts.replace('-', '').replace(':', '')
-- 
2.6.4 (Apple Git-63)


From 2f14283dc8d375fa4dd7c43135e17e2f3d23a9b1 Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Mon, 22 May 2017 14:19:48 -0400
Subject: [PATCH 33/45] Fixed

---
 airflow/models.py | 6 ++++--
 1 file changed, 4 insertions(+), 2 deletions(-)

diff --git a/airflow/models.py b/airflow/models.py
index 77314c1..add1d2b 100755
--- a/airflow/models.py
+++ b/airflow/models.py
@@ -1661,8 +1661,10 @@ class TaskInstance(Base, LoggingMixin):
         prev_ds = prev_execution_date.isoformat()[:10]
         next_execution_date = task.dag.following_schedule(self.execution_date)
         next_ds = next_execution_date.isoformat()[:10]
-        month_first_ds = self.execution_date.replace(day=1)
-        month_last_ds = self.execution_date.replace(day=calendar.monthrange(self.execution_date.year, self.execution_date.month)[1])
+        month_first_date = self.execution_date.replace(day=1)
+        month_first_ds = month_first_date.isoformat()[:10]
+        month_last_date = self.execution_date.replace(day=calendar.monthrange(self.execution_date.year, self.execution_date.month)[1])
+        month_last_ds = month_last_date.isoformat()[:10]
 
         ds_nodash = ds.replace('-', '')
         ts_nodash = ts.replace('-', '').replace(':', '')
-- 
2.6.4 (Apple Git-63)


From 8dcde871e2c2b337b542e15e870867f8436eb738 Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Wed, 28 Jun 2017 16:05:58 -0400
Subject: [PATCH 34/45] Use templates in templated fields

---
 airflow/models.py | 18 ++++++++++++++++--
 1 file changed, 16 insertions(+), 2 deletions(-)

diff --git a/airflow/models.py b/airflow/models.py
index add1d2b..ed84df3 100755
--- a/airflow/models.py
+++ b/airflow/models.py
@@ -1777,8 +1777,22 @@ class TaskInstance(Base, LoggingMixin):
         for attr in task.__class__.template_fields:
             content = getattr(task, attr)
             if content:
-                rendered_content = rt(attr, content, jinja_context)
-                setattr(task, attr, rendered_content)
+                last_content = content
+                done_rendering = False
+                iterations = 0
+                while not done_rendering:
+                    rendered_content = rt(attr, last_content, jinja_context)
+                    if iterations > 5:
+                        logging.info('Stuck in loop!!!!')
+                        break
+
+                    if last_content == rendered_content:
+                        done_rendering = True
+
+                    last_content = rendered_content
+                    iterations += 1
+
+                setattr(task, attr, last_content)
 
     def email_alert(self, exception, is_retry=False):
         task = self.task
-- 
2.6.4 (Apple Git-63)


From 3f422a3ec4e25beda560da21bd5764f4f2dcdf0e Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Tue, 1 Aug 2017 14:14:30 -0400
Subject: [PATCH 35/45] Reduce column id size to 191

---
 .../migrations/versions/1b38cef5b76e_add_dagrun.py |  4 ++--
 .../64de9cddf6c9_add_task_fails_journal_table.py   |  4 ++--
 .../versions/e3a246e0dc1_current_schema.py         | 28 +++++++++++-----------
 .../versions/f2ca10b85618_add_dag_stats_table.py   |  2 +-
 airflow/models.py                                  |  2 +-
 5 files changed, 20 insertions(+), 20 deletions(-)

diff --git a/airflow/migrations/versions/1b38cef5b76e_add_dagrun.py b/airflow/migrations/versions/1b38cef5b76e_add_dagrun.py
index 7da9ee7..f0bb31d 100644
--- a/airflow/migrations/versions/1b38cef5b76e_add_dagrun.py
+++ b/airflow/migrations/versions/1b38cef5b76e_add_dagrun.py
@@ -34,10 +34,10 @@ from sqlalchemy.dialects import mysql
 def upgrade():
     op.create_table('dag_run',
         sa.Column('id', sa.Integer(), nullable=False),
-        sa.Column('dag_id', sa.String(length=250), nullable=True),
+        sa.Column('dag_id', sa.String(length=191), nullable=True),
         sa.Column('execution_date', sa.DateTime(), nullable=True),
         sa.Column('state', sa.String(length=50), nullable=True),
-        sa.Column('run_id', sa.String(length=250), nullable=True),
+        sa.Column('run_id', sa.String(length=191), nullable=True),
         sa.Column('external_trigger', sa.Boolean(), nullable=True),
         sa.PrimaryKeyConstraint('id'),
         sa.UniqueConstraint('dag_id', 'execution_date'),
diff --git a/airflow/migrations/versions/64de9cddf6c9_add_task_fails_journal_table.py b/airflow/migrations/versions/64de9cddf6c9_add_task_fails_journal_table.py
index 3d5c7a4..1f38f34 100644
--- a/airflow/migrations/versions/64de9cddf6c9_add_task_fails_journal_table.py
+++ b/airflow/migrations/versions/64de9cddf6c9_add_task_fails_journal_table.py
@@ -33,8 +33,8 @@ def upgrade():
     op.create_table(
         'task_fail',
         sa.Column('id', sa.Integer(), nullable=False),
-        sa.Column('task_id', sa.String(length=250), nullable=False),
-        sa.Column('dag_id', sa.String(length=250), nullable=False),
+        sa.Column('task_id', sa.String(length=191), nullable=False),
+        sa.Column('dag_id', sa.String(length=191), nullable=False),
         sa.Column('execution_date', sa.DateTime(), nullable=False),
         sa.Column('start_date', sa.DateTime(), nullable=True),
         sa.Column('end_date', sa.DateTime(), nullable=True),
diff --git a/airflow/migrations/versions/e3a246e0dc1_current_schema.py b/airflow/migrations/versions/e3a246e0dc1_current_schema.py
index c1cb9c6..b6ca2e6 100644
--- a/airflow/migrations/versions/e3a246e0dc1_current_schema.py
+++ b/airflow/migrations/versions/e3a246e0dc1_current_schema.py
@@ -40,7 +40,7 @@ def upgrade():
         op.create_table(
             'connection',
             sa.Column('id', sa.Integer(), nullable=False),
-            sa.Column('conn_id', sa.String(length=250), nullable=True),
+            sa.Column('conn_id', sa.String(length=191), nullable=True),
             sa.Column('conn_type', sa.String(length=500), nullable=True),
             sa.Column('host', sa.String(length=500), nullable=True),
             sa.Column('schema', sa.String(length=500), nullable=True),
@@ -53,7 +53,7 @@ def upgrade():
     if 'dag' not in tables:
         op.create_table(
             'dag',
-            sa.Column('dag_id', sa.String(length=250), nullable=False),
+            sa.Column('dag_id', sa.String(length=191), nullable=False),
             sa.Column('is_paused', sa.Boolean(), nullable=True),
             sa.Column('is_subdag', sa.Boolean(), nullable=True),
             sa.Column('is_active', sa.Boolean(), nullable=True),
@@ -88,7 +88,7 @@ def upgrade():
         op.create_table(
             'job',
             sa.Column('id', sa.Integer(), nullable=False),
-            sa.Column('dag_id', sa.String(length=250), nullable=True),
+            sa.Column('dag_id', sa.String(length=191), nullable=True),
             sa.Column('state', sa.String(length=20), nullable=True),
             sa.Column('job_type', sa.String(length=30), nullable=True),
             sa.Column('start_date', sa.DateTime(), nullable=True),
@@ -117,8 +117,8 @@ def upgrade():
             'log',
             sa.Column('id', sa.Integer(), nullable=False),
             sa.Column('dttm', sa.DateTime(), nullable=True),
-            sa.Column('dag_id', sa.String(length=250), nullable=True),
-            sa.Column('task_id', sa.String(length=250), nullable=True),
+            sa.Column('dag_id', sa.String(length=191), nullable=True),
+            sa.Column('task_id', sa.String(length=191), nullable=True),
             sa.Column('event', sa.String(length=30), nullable=True),
             sa.Column('execution_date', sa.DateTime(), nullable=True),
             sa.Column('owner', sa.String(length=500), nullable=True),
@@ -127,8 +127,8 @@ def upgrade():
     if 'sla_miss' not in tables:
         op.create_table(
             'sla_miss',
-            sa.Column('task_id', sa.String(length=250), nullable=False),
-            sa.Column('dag_id', sa.String(length=250), nullable=False),
+            sa.Column('task_id', sa.String(length=191), nullable=False),
+            sa.Column('dag_id', sa.String(length=191), nullable=False),
             sa.Column('execution_date', sa.DateTime(), nullable=False),
             sa.Column('email_sent', sa.Boolean(), nullable=True),
             sa.Column('timestamp', sa.DateTime(), nullable=True),
@@ -148,8 +148,8 @@ def upgrade():
     if 'task_instance' not in tables:
         op.create_table(
             'task_instance',
-            sa.Column('task_id', sa.String(length=250), nullable=False),
-            sa.Column('dag_id', sa.String(length=250), nullable=False),
+            sa.Column('task_id', sa.String(length=191), nullable=False),
+            sa.Column('dag_id', sa.String(length=191), nullable=False),
             sa.Column('execution_date', sa.DateTime(), nullable=False),
             sa.Column('start_date', sa.DateTime(), nullable=True),
             sa.Column('end_date', sa.DateTime(), nullable=True),
@@ -187,7 +187,7 @@ def upgrade():
         op.create_table(
             'user',
             sa.Column('id', sa.Integer(), nullable=False),
-            sa.Column('username', sa.String(length=250), nullable=True),
+            sa.Column('username', sa.String(length=191), nullable=True),
             sa.Column('email', sa.String(length=500), nullable=True),
             sa.PrimaryKeyConstraint('id'),
             sa.UniqueConstraint('username')
@@ -196,7 +196,7 @@ def upgrade():
         op.create_table(
             'variable',
             sa.Column('id', sa.Integer(), nullable=False),
-            sa.Column('key', sa.String(length=250), nullable=True),
+            sa.Column('key', sa.String(length=191), nullable=True),
             sa.Column('val', sa.Text(), nullable=True),
             sa.PrimaryKeyConstraint('id'),
             sa.UniqueConstraint('key')
@@ -206,7 +206,7 @@ def upgrade():
             'chart',
             sa.Column('id', sa.Integer(), nullable=False),
             sa.Column('label', sa.String(length=200), nullable=True),
-            sa.Column('conn_id', sa.String(length=250), nullable=False),
+            sa.Column('conn_id', sa.String(length=191), nullable=False),
             sa.Column('user_id', sa.Integer(), nullable=True),
             sa.Column('chart_type', sa.String(length=100), nullable=True),
             sa.Column('sql_layout', sa.String(length=50), nullable=True),
@@ -249,8 +249,8 @@ def upgrade():
                 default=func.now(),
                 nullable=False),
             sa.Column('execution_date', sa.DateTime(), nullable=False),
-            sa.Column('task_id', sa.String(length=250), nullable=False),
-            sa.Column('dag_id', sa.String(length=250), nullable=False),
+            sa.Column('task_id', sa.String(length=191), nullable=False),
+            sa.Column('dag_id', sa.String(length=191), nullable=False),
             sa.PrimaryKeyConstraint('id')
         )
 
diff --git a/airflow/migrations/versions/f2ca10b85618_add_dag_stats_table.py b/airflow/migrations/versions/f2ca10b85618_add_dag_stats_table.py
index dabe812..0eb237f 100644
--- a/airflow/migrations/versions/f2ca10b85618_add_dag_stats_table.py
+++ b/airflow/migrations/versions/f2ca10b85618_add_dag_stats_table.py
@@ -31,7 +31,7 @@ import sqlalchemy as sa
 
 def upgrade():
     op.create_table('dag_stats',
-                    sa.Column('dag_id', sa.String(length=250), nullable=False),
+                    sa.Column('dag_id', sa.String(length=191), nullable=False),
                     sa.Column('state', sa.String(length=50), nullable=False),
                     sa.Column('count', sa.Integer(), nullable=False, default=0),
                     sa.Column('dirty', sa.Boolean(), nullable=False, default=False),
diff --git a/airflow/models.py b/airflow/models.py
index ed84df3..ea08fe7 100755
--- a/airflow/models.py
+++ b/airflow/models.py
@@ -84,7 +84,7 @@ from airflow.utils.trigger_rule import TriggerRule
 from airflow.utils.log.logging_mixin import LoggingMixin
 
 Base = declarative_base()
-ID_LEN = 250
+ID_LEN = 191
 XCOM_RETURN_KEY = 'return_value'
 
 Stats = settings.Stats
-- 
2.6.4 (Apple Git-63)


From f718af49f0bae5682d5293cb209f07d29d9326e1 Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Tue, 1 Aug 2017 14:28:09 -0400
Subject: [PATCH 36/45] Ignore fractional seconds to support older mysql

---
 ...236f1_add_fractional_seconds_to_mysql_tables.py | 52 +++++++++++-----------
 1 file changed, 26 insertions(+), 26 deletions(-)

diff --git a/airflow/migrations/versions/4addfa1236f1_add_fractional_seconds_to_mysql_tables.py b/airflow/migrations/versions/4addfa1236f1_add_fractional_seconds_to_mysql_tables.py
index c1c6de3..053b120 100644
--- a/airflow/migrations/versions/4addfa1236f1_add_fractional_seconds_to_mysql_tables.py
+++ b/airflow/migrations/versions/4addfa1236f1_add_fractional_seconds_to_mysql_tables.py
@@ -33,42 +33,42 @@ from alembic import context
 
 def upgrade():
     if context.config.get_main_option('sqlalchemy.url').startswith('mysql'):
-        op.alter_column(table_name='dag', column_name='last_scheduler_run', type_=mysql.DATETIME(fsp=6))
-        op.alter_column(table_name='dag', column_name='last_pickled', type_=mysql.DATETIME(fsp=6))
-        op.alter_column(table_name='dag', column_name='last_expired', type_=mysql.DATETIME(fsp=6))
+        op.alter_column(table_name='dag', column_name='last_scheduler_run', type_=mysql.DATETIME())
+        op.alter_column(table_name='dag', column_name='last_pickled', type_=mysql.DATETIME())
+        op.alter_column(table_name='dag', column_name='last_expired', type_=mysql.DATETIME())
 
-        op.alter_column(table_name='dag_pickle', column_name='created_dttm', type_=mysql.DATETIME(fsp=6))
+        op.alter_column(table_name='dag_pickle', column_name='created_dttm', type_=mysql.DATETIME())
 
-        op.alter_column(table_name='dag_run', column_name='execution_date', type_=mysql.DATETIME(fsp=6))
-        op.alter_column(table_name='dag_run', column_name='start_date', type_=mysql.DATETIME(fsp=6))
-        op.alter_column(table_name='dag_run', column_name='end_date', type_=mysql.DATETIME(fsp=6))
+        op.alter_column(table_name='dag_run', column_name='execution_date', type_=mysql.DATETIME())
+        op.alter_column(table_name='dag_run', column_name='start_date', type_=mysql.DATETIME())
+        op.alter_column(table_name='dag_run', column_name='end_date', type_=mysql.DATETIME())
 
-        op.alter_column(table_name='import_error', column_name='timestamp', type_=mysql.DATETIME(fsp=6))
+        op.alter_column(table_name='import_error', column_name='timestamp', type_=mysql.DATETIME())
 
-        op.alter_column(table_name='job', column_name='start_date', type_=mysql.DATETIME(fsp=6))
-        op.alter_column(table_name='job', column_name='end_date', type_=mysql.DATETIME(fsp=6))
-        op.alter_column(table_name='job', column_name='latest_heartbeat', type_=mysql.DATETIME(fsp=6))
+        op.alter_column(table_name='job', column_name='start_date', type_=mysql.DATETIME())
+        op.alter_column(table_name='job', column_name='end_date', type_=mysql.DATETIME())
+        op.alter_column(table_name='job', column_name='latest_heartbeat', type_=mysql.DATETIME())
 
-        op.alter_column(table_name='known_event', column_name='start_date', type_=mysql.DATETIME(fsp=6))
-        op.alter_column(table_name='known_event', column_name='end_date', type_=mysql.DATETIME(fsp=6))
+        op.alter_column(table_name='known_event', column_name='start_date', type_=mysql.DATETIME())
+        op.alter_column(table_name='known_event', column_name='end_date', type_=mysql.DATETIME())
 
-        op.alter_column(table_name='log', column_name='dttm', type_=mysql.DATETIME(fsp=6))
-        op.alter_column(table_name='log', column_name='execution_date', type_=mysql.DATETIME(fsp=6))
+        op.alter_column(table_name='log', column_name='dttm', type_=mysql.DATETIME())
+        op.alter_column(table_name='log', column_name='execution_date', type_=mysql.DATETIME())
 
-        op.alter_column(table_name='sla_miss', column_name='execution_date', type_=mysql.DATETIME(fsp=6), nullable=False)
-        op.alter_column(table_name='sla_miss', column_name='timestamp', type_=mysql.DATETIME(fsp=6))
+        op.alter_column(table_name='sla_miss', column_name='execution_date', type_=mysql.DATETIME(), nullable=False)
+        op.alter_column(table_name='sla_miss', column_name='timestamp', type_=mysql.DATETIME())
 
-        op.alter_column(table_name='task_fail', column_name='execution_date', type_=mysql.DATETIME(fsp=6))
-        op.alter_column(table_name='task_fail', column_name='start_date', type_=mysql.DATETIME(fsp=6))
-        op.alter_column(table_name='task_fail', column_name='end_date', type_=mysql.DATETIME(fsp=6))
+        op.alter_column(table_name='task_fail', column_name='execution_date', type_=mysql.DATETIME())
+        op.alter_column(table_name='task_fail', column_name='start_date', type_=mysql.DATETIME())
+        op.alter_column(table_name='task_fail', column_name='end_date', type_=mysql.DATETIME())
 
-        op.alter_column(table_name='task_instance', column_name='execution_date', type_=mysql.DATETIME(fsp=6), nullable=False)
-        op.alter_column(table_name='task_instance', column_name='start_date', type_=mysql.DATETIME(fsp=6))
-        op.alter_column(table_name='task_instance', column_name='end_date', type_=mysql.DATETIME(fsp=6))
-        op.alter_column(table_name='task_instance', column_name='queued_dttm', type_=mysql.DATETIME(fsp=6))
+        op.alter_column(table_name='task_instance', column_name='execution_date', type_=mysql.DATETIME(), nullable=False)
+        op.alter_column(table_name='task_instance', column_name='start_date', type_=mysql.DATETIME())
+        op.alter_column(table_name='task_instance', column_name='end_date', type_=mysql.DATETIME())
+        op.alter_column(table_name='task_instance', column_name='queued_dttm', type_=mysql.DATETIME())
 
-        op.alter_column(table_name='xcom', column_name='timestamp', type_=mysql.DATETIME(fsp=6))
-        op.alter_column(table_name='xcom', column_name='execution_date', type_=mysql.DATETIME(fsp=6))
+        op.alter_column(table_name='xcom', column_name='timestamp', type_=mysql.DATETIME())
+        op.alter_column(table_name='xcom', column_name='execution_date', type_=mysql.DATETIME())
 
 
 def downgrade():
-- 
2.6.4 (Apple Git-63)


From 8d8bc5071f44e87caac22cac3af7f2a887d92b37 Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Sat, 19 Aug 2017 08:37:50 -0400
Subject: [PATCH 37/45] Include all dag states in latest run

---
 airflow/models.py                         | 24 +++++++++++++++++++++++-
 airflow/www/api/experimental/endpoints.py |  2 +-
 2 files changed, 24 insertions(+), 2 deletions(-)

diff --git a/airflow/models.py b/airflow/models.py
index ea08fe7..fa7c2db 100755
--- a/airflow/models.py
+++ b/airflow/models.py
@@ -26,7 +26,7 @@ from builtins import str
 from builtins import object, bytes
 import copy
 from collections import namedtuple
-from datetime import datetime, timedelta, date
+from datetime import datetime, timedelta
 import dill
 import functools
 import getpass
@@ -4764,6 +4764,28 @@ class DagRun(Base, LoggingMixin):
         )
         return dagruns
 
+    @classmethod
+    @provide_session
+    def get_all_latest_runs(cls, session):
+        """Returns the latest running DagRun for each DAG. """
+        subquery = (
+            session
+            .query(
+                cls.dag_id,
+                func.max(cls.execution_date).label('execution_date'))
+            .group_by(cls.dag_id)
+            .subquery()
+        )
+        dagruns = (
+            session
+            .query(cls)
+            .join(subquery,
+                  and_(cls.dag_id == subquery.c.dag_id,
+                       cls.execution_date == subquery.c.execution_date))
+            .all()
+        )
+        return dagruns
+
 
 class Pool(Base):
     __tablename__ = "slot_pool"
diff --git a/airflow/www/api/experimental/endpoints.py b/airflow/www/api/experimental/endpoints.py
index b5a3052..b83c5b5 100644
--- a/airflow/www/api/experimental/endpoints.py
+++ b/airflow/www/api/experimental/endpoints.py
@@ -156,7 +156,7 @@ def task_instance_info(dag_id, execution_date, task_id):
 def latest_dag_runs():
     """Returns the latest DagRun for each DAG formatted for the UI. """
     from airflow.models import DagRun
-    dagruns = DagRun.get_latest_runs()
+    dagruns = DagRun.get_all_latest_runs()
     payload = []
     for dagrun in dagruns:
         if dagrun.execution_date:
-- 
2.6.4 (Apple Git-63)


From db84530377cb4122bb3e801f4f5358d1782ed9a3 Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Wed, 20 Sep 2017 16:38:24 -0400
Subject: [PATCH 38/45] Remove excessive logging

---
 airflow/utils/db.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/airflow/utils/db.py b/airflow/utils/db.py
index c3aabb3..463ec8a 100644
--- a/airflow/utils/db.py
+++ b/airflow/utils/db.py
@@ -51,7 +51,7 @@ def provide_session(func):
 
         if not (session_in_kwargs or session_in_args):
             needs_session = True
-            log.info("Injecting session into %s" % func.__name__)
+            #logging.info("Injecting session into %s" % func.__name__)
             # traceback.print_stack()
             session = settings.Session()
             kwargs[arg_session] = session
-- 
2.6.4 (Apple Git-63)


From dc144c0a7c60881c2776f5cc08ec20436b72a231 Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Thu, 5 Oct 2017 16:26:36 -0400
Subject: [PATCH 39/45] None checks around prev_ds

---
 airflow/models.py | 8 ++++----
 1 file changed, 4 insertions(+), 4 deletions(-)

diff --git a/airflow/models.py b/airflow/models.py
index fa7c2db..c4dff63 100755
--- a/airflow/models.py
+++ b/airflow/models.py
@@ -1658,9 +1658,9 @@ class TaskInstance(Base, LoggingMixin):
         yesterday_ds = (self.execution_date - timedelta(1)).isoformat()[:10]
         tomorrow_ds = (self.execution_date + timedelta(1)).isoformat()[:10]
         prev_execution_date = task.dag.previous_schedule(self.execution_date)
-        prev_ds = prev_execution_date.isoformat()[:10]
+        prev_ds = prev_execution_date.isoformat()[:10] if prev_execution_date else None
         next_execution_date = task.dag.following_schedule(self.execution_date)
-        next_ds = next_execution_date.isoformat()[:10]
+        next_ds = next_execution_date.isoformat()[:10] if next_execution_date else None
         month_first_date = self.execution_date.replace(day=1)
         month_first_ds = month_first_date.isoformat()[:10]
         month_last_date = self.execution_date.replace(day=calendar.monthrange(self.execution_date.year, self.execution_date.month)[1])
@@ -1670,8 +1670,8 @@ class TaskInstance(Base, LoggingMixin):
         ts_nodash = ts.replace('-', '').replace(':', '')
         yesterday_ds_nodash = yesterday_ds.replace('-', '')
         tomorrow_ds_nodash = tomorrow_ds.replace('-', '')
-        prev_ds_nodash = prev_ds.replace('-', '')
-        next_ds_nodash = next_ds.replace('-', '')
+        prev_ds_nodash = prev_ds.replace('-', '') if prev_ds else None
+        next_ds_nodash = next_ds.replace('-', '') if next_ds else None
         month_first_ds_nodash = month_first_ds.replace('-', '')
         month_last_ds_nodash = month_last_ds.replace('-', '')
 
-- 
2.6.4 (Apple Git-63)


From a89722beccab3ca1fdaa61f8994eb0bd33ad7fab Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Mon, 6 Nov 2017 15:15:58 -0500
Subject: [PATCH 40/45] Post merge 1.9

---
 airflow/task_runner/base_task_runner.py   | 3 ---
 airflow/utils/db.py                       | 2 --
 airflow/www/api/experimental/endpoints.py | 2 +-
 3 files changed, 1 insertion(+), 6 deletions(-)

diff --git a/airflow/task_runner/base_task_runner.py b/airflow/task_runner/base_task_runner.py
index ef4112d..963691e 100644
--- a/airflow/task_runner/base_task_runner.py
+++ b/airflow/task_runner/base_task_runner.py
@@ -11,7 +11,6 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from __future__ import unicode_literals
 
 import getpass
 import os
@@ -19,8 +18,6 @@ import json
 import subprocess
 import threading
 
-from airflow.utils.log.logging_mixin import LoggingMixin
-
 from airflow import configuration as conf
 from tempfile import mkstemp
 
diff --git a/airflow/utils/db.py b/airflow/utils/db.py
index 463ec8a..e85592d 100644
--- a/airflow/utils/db.py
+++ b/airflow/utils/db.py
@@ -51,8 +51,6 @@ def provide_session(func):
 
         if not (session_in_kwargs or session_in_args):
             needs_session = True
-            #logging.info("Injecting session into %s" % func.__name__)
-            # traceback.print_stack()
             session = settings.Session()
             kwargs[arg_session] = session
         result = func(*args, **kwargs)
diff --git a/airflow/www/api/experimental/endpoints.py b/airflow/www/api/experimental/endpoints.py
index b83c5b5..b5a3052 100644
--- a/airflow/www/api/experimental/endpoints.py
+++ b/airflow/www/api/experimental/endpoints.py
@@ -156,7 +156,7 @@ def task_instance_info(dag_id, execution_date, task_id):
 def latest_dag_runs():
     """Returns the latest DagRun for each DAG formatted for the UI. """
     from airflow.models import DagRun
-    dagruns = DagRun.get_all_latest_runs()
+    dagruns = DagRun.get_latest_runs()
     payload = []
     for dagrun in dagruns:
         if dagrun.execution_date:
-- 
2.6.4 (Apple Git-63)


From 05f4c1d8981cdca4ca4fbe97a1fa7e0da354fa26 Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Mon, 6 Nov 2017 19:19:03 -0500
Subject: [PATCH 41/45] fixed merge

---
 airflow/ti_deps/deps/dag_ti_slots_available_dep.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/airflow/ti_deps/deps/dag_ti_slots_available_dep.py b/airflow/ti_deps/deps/dag_ti_slots_available_dep.py
index c46f37d..799d1cc 100644
--- a/airflow/ti_deps/deps/dag_ti_slots_available_dep.py
+++ b/airflow/ti_deps/deps/dag_ti_slots_available_dep.py
@@ -21,7 +21,7 @@ class DagTISlotsAvailableDep(BaseTIDep):
 
     @provide_session
     def _get_dep_statuses(self, ti, session, dep_context):
-        if ti.task.dag.concurrency_reached(session=session):
+        if ti.task.dag.concurrency_reached:
             yield self._failing_status(
                 reason="The maximum number of running tasks ({0}) for this task's DAG "
                        "'{1}' has been reached.".format(ti.task.dag.concurrency,
-- 
2.6.4 (Apple Git-63)


From 8b0d95ebd535a7bce48af5a146dcd20e120cc0c9 Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Mon, 6 Nov 2017 21:31:45 -0500
Subject: [PATCH 42/45] removed executor

---
 airflow/executors/base_executor.py | 4 +---
 1 file changed, 1 insertion(+), 3 deletions(-)

diff --git a/airflow/executors/base_executor.py b/airflow/executors/base_executor.py
index 543624b..b8a0428 100644
--- a/airflow/executors/base_executor.py
+++ b/airflow/executors/base_executor.py
@@ -58,8 +58,7 @@ class BaseExecutor(LoggingMixin):
             ignore_depends_on_past=False,
             ignore_task_deps=False,
             ignore_ti_state=False,
-            pool=None,
-            dag_executor=None):
+            pool=None):
         pool = pool or task_instance.pool
         command = task_instance.command(
             local=True,
@@ -69,7 +68,6 @@ class BaseExecutor(LoggingMixin):
             ignore_task_deps=ignore_task_deps,
             ignore_ti_state=ignore_ti_state,
             pool=pool,
-            dag_executor=dag_executor,
             pickle_id=pickle_id)
         self.queue_command(
             task_instance,
-- 
2.6.4 (Apple Git-63)


From 65b79c6319f9d6f2822225d8138a110f901441b2 Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Tue, 19 Dec 2017 17:33:25 -0500
Subject: [PATCH 43/45] logging mixin

---
 airflow/task_runner/base_task_runner.py | 1 +
 1 file changed, 1 insertion(+)

diff --git a/airflow/task_runner/base_task_runner.py b/airflow/task_runner/base_task_runner.py
index 963691e..3ac99f4 100644
--- a/airflow/task_runner/base_task_runner.py
+++ b/airflow/task_runner/base_task_runner.py
@@ -18,6 +18,7 @@ import json
 import subprocess
 import threading
 
+from airflow import LoggingMixin
 from airflow import configuration as conf
 from tempfile import mkstemp
 
-- 
2.6.4 (Apple Git-63)


From 73c5939411477f26d8afc1828ac3787c8355c11a Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Fri, 23 Mar 2018 15:47:07 -0400
Subject: [PATCH 44/45] force version of dataflow to 2.2

---
 setup.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/setup.py b/setup.py
index c36b315..ebe2a30 100644
--- a/setup.py
+++ b/setup.py
@@ -131,7 +131,7 @@ gcp_api = [
     'google-api-python-client>=1.5.0, <1.6.0',
     'oauth2client>=2.0.2, <2.1.0',
     'PyOpenSSL',
-    'google-cloud-dataflow',
+    'google-cloud-dataflow==2.2.0',
     'pandas-gbq'
 ]
 hdfs = ['snakebite>=2.7.8']
-- 
2.6.4 (Apple Git-63)


From 952d2b4109ba4e7a80866a0b7463444a7bac13f6 Mon Sep 17 00:00:00 2001
From: Chris Fei <chris@indicative.com>
Date: Tue, 8 May 2018 18:38:22 -0400
Subject: [PATCH 45/45] ch

---
 airflow/www/views.py | 8 ++++++--
 1 file changed, 6 insertions(+), 2 deletions(-)

diff --git a/airflow/www/views.py b/airflow/www/views.py
index 63af88f..7e8d048 100644
--- a/airflow/www/views.py
+++ b/airflow/www/views.py
@@ -1135,6 +1135,10 @@ class Airflow(BaseView):
         dag_id = request.args.get('dag_id')
         blur = conf.getboolean('webserver', 'demo_mode')
         dag = dagbag.get_dag(dag_id)
+        if not dag:
+            dagbag.collect_dags(only_if_updated=False)
+            dag = dagbag.get_dag(dag_id)
+
         root = request.args.get('root')
         if root:
             dag = dag.sub_dag(
@@ -1146,7 +1150,7 @@ class Airflow(BaseView):
 
         base_date = request.args.get('base_date')
         num_runs = request.args.get('num_runs')
-        num_runs = int(num_runs) if num_runs else 25
+        num_runs = int(num_runs) if num_runs else 5
 
         if base_date:
             base_date = dateutil.parser.parse(base_date)
@@ -1238,7 +1242,7 @@ class Airflow(BaseView):
                 for d in dates],
         }
 
-        data = json.dumps(data, indent=4, default=json_ser)
+        data = json.dumps(data, indent=None, default=json_ser)
         session.commit()
         session.close()
 
-- 
2.6.4 (Apple Git-63)

